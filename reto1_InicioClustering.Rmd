---
title: "Reto 1"
author: "Blockchain Patrol"
date: "2023-11-06"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Crypto Datathon Reto 1

```{r message= FALSE, warning=FALSE}

library(data.table)
library(tidyverse)
library(readr)
library(ggplot2)
library(PerformanceAnalytics)
library(dygraphs)
library(tidyr)
library(cluster)
library(NbClust)
library(fpc) 
library(factoextra)
library(corrplot)

```

## Carga y limpieza de los datos

Carga en primer lugar la información cualitativa de las monedas.

```{r message= FALSE, warning=FALSE}

info_cualitativa <- read_csv2('./Data/informacion_cualitativa_monedas_reto1.csv', show_col_types = FALSE)
str(info_cualitativa)

```

```{r message= FALSE, warning=FALSE}

summary(info_cualitativa)

```

Carga de datos de monedas en un único dataset

```{r message= FALSE, warning=FALSE}

info_cuantitativa <-
  list.files(path = 'Data/Información cuantitativa monedas_reto1', pattern = "*.csv", full.names = TRUE, recursive = TRUE) %>%
  map_df(~fread(.x, drop = 'V1') %>% add_column(Currency = sub(pattern = "(.*)\\..*$", replacement = "\\1", basename(.x)), .before = 0))

str(info_cuantitativa)

```


```{r message= FALSE, warning=FALSE}

summary(info_cuantitativa)

```

Calculamos el rendimiendo diario (total y en porcentaje). Los vamos a utilizar luego para las métricas y en más sitios.

Rendimiento Diario = [(Precio de Cierre Actual - Precio de Cierre del Día Anterior) / Precio de Cierre del Día Anterior] * 100

```{r message= FALSE, warning=FALSE}

info_cuantitativa <- info_cuantitativa %>%
  group_by(Currency) %>%
  arrange(Date) %>%
  #Alberto: esto lo he cambiado yo porque entiendo quie el return lo queremos en absoluto, no en relativo
  mutate(Return = Close - lag(Close)) %>%
  mutate(Return_Pctg = 100*(Close - lag(Close))/lag(Close))

# Sustituimos los valores que son NaN e Inf por NA
info_cuantitativa$Return[is.nan(info_cuantitativa$Return)] <- NA
info_cuantitativa$Return_Pctg[is.nan(info_cuantitativa$Return_Pctg)] <- NA
info_cuantitativa$Return[is.infinite(info_cuantitativa$Return)] <- NA
info_cuantitativa$Return_Pctg[is.infinite(info_cuantitativa$Return_Pctg)] <- NA

summary(info_cuantitativa)

```

## Análisis de datos

```{r message= FALSE, warning=FALSE}
#Preguntar a Sergio por volatility
crypto_summary_by_currency <- info_cuantitativa %>%
  group_by(Currency) %>%
  summarise(`Market Cap` = mean(`Market Cap`), Volume = mean(Volume), Volatility = sd(Return_Pctg, na.rm=TRUE))

crypto_summary_by_currency

```


## Top 10

Por capitalización

```{r message= FALSE, warning=FALSE}
#Por qué no usas la vaiable anterior en lugar de volver a grupar?
top_cap <- info_cuantitativa %>%
  group_by(Currency) %>%
  summarise(`Market Cap` = mean(`Market Cap`)) %>%
  top_n(10, `Market Cap`) %>%
  arrange(desc(`Market Cap`))

```

Por volumen

```{r message= FALSE, warning=FALSE}

top_volume <- info_cuantitativa %>%
  group_by(Currency) %>%
  summarise(Volume = mean(Volume)) %>%
  top_n(10, Volume) %>%
  arrange(desc(Volume))

```

Por volatilidad (se mide como la desviación estándar del retorno diario. El retorno se calcula como el precio de cierre del menos el precio de cierre del día anterior dividido entre el precio de cierre del día anterior)

```{r message= FALSE, warning=FALSE}

top_volatility <- info_cuantitativa %>%
  group_by(Currency) %>%
  summarize(Volatility = sd(Return_Pctg, na.rm=TRUE)) %>%
  top_n(10, Volatility) %>%
  arrange(desc(Volatility))

```


## Plot

Nos quedamos con las diez acciones que tienen más capitalización de mercado

```{r message= FALSE, warning=FALSE}

info_cuantitativa_top <- filter(info_cuantitativa, Currency %in% top_cap$Currency)

```

Gráfica de evolución de los precios

```{r message= FALSE, warning=FALSE}

ggplot(data = info_cuantitativa_top) +
  geom_line(aes(x = Date, y = Close)) +
  facet_wrap("Currency", nrow  = 3, scales = "free") +
  #Alberto: incluyo el año porque me oarece que s ve algo mejor así. Cambio el nrow y añado size
  scale_x_date(date_labels = "%b %y")+
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size=4))
  

```


Gráfica de retorno

```{r message= FALSE, warning=FALSE}

ggplot(data = info_cuantitativa_top) +
  geom_line(aes(x = Date, y = Return_Pctg)) +
  facet_wrap("Currency", nrow  = 5, scales = "free") +
  scale_x_date(date_labels = "%b")

```

convertimos a objeto xts

```{r message= FALSE, warning=FALSE}

info_cuantitativa_ts_bitcoin <- info_cuantitativa %>%
  ungroup() %>%
  filter(Currency == "Bitcoin") %>%
  select(Date, Close, Return_Pctg)

info_cuantitativa_ts_bitcoin <- as.xts(info_cuantitativa_ts_bitcoin[, -1], order.by = as.Date(info_cuantitativa_ts_bitcoin$Date))

```

```{r message= FALSE, warning=FALSE}

dygraph(info_cuantitativa_ts_bitcoin$Close, main = "Bitcoin") %>%
  dyAxis("y", label = "%") %>%
  dyOptions(colors = RColorBrewer::brewer.pal(3, "Set2"))

```

## Métricas

#Sharpe Ratio

(Rendimiento Promedio - Tasa de Rendimiento Libre de Riesgo) / Desviación Estándar de los Rendimientos Diarios

- Rendimiento Diario = [(Precio de Cierre Actual - Precio de Cierre del Día Anterior) / Precio de Cierre del Día Anterior] * 100

- Rendimiento libre de riesgo: Necesitas tener una tasa de interés libre de riesgo para usar en tu cálculo. Esto podría ser la tasa de interés de un bono del gobierno a corto plazo.

```{r message= FALSE, warning=FALSE}

ts_monedas_top <- info_cuantitativa %>%
  filter(Currency %in% top_cap$Currency) %>%
  select(Date, Return_Pctg) %>%
  spread(Currency, Return_Pctg)

ts_monedas_top2 <- as.xts(ts_monedas_top[, -1], order.by = as.Date(ts_monedas_top$Date))

round(SharpeRatio(ts_monedas_top2[, , drop = FALSE], Rf = .0003, FUN = "StdDev"), 4)

```

Hemos asumido una tasa de riesgo libre del 0.03%.

El índice de Sharpe mide el rendimiento por unidad de riesgo. Cuanto mayor es su valor mejor es el ratio entre riesgo y rendimiento que tiene una inversión.

#Network Value To Transactions (NVT)

```{r message= FALSE, warning=FALSE}

nvt <- info_cuantitativa %>%
  filter(Currency %in% top_cap$Currency) %>%
  group_by(Currency) %>%
  summarize(NVT = sum(`Market Cap`) / sum(Volume))

nvt

```


Vamos a hacer temas de clustering.

Vamos a añadir a crypto_summary_by_currency el Sharpe Ratio y el NVT



```{r}
#Este es un cálculo guarro para crear el SR y NVT de TODAS las criptos. Ver si reaprovechar código de Sergio
calculoSR <- info_cuantitativa %>%
  filter(Currency %in% crypto_summary_by_currency$Currency) %>%
  select(Date, Return_Pctg) %>%
  spread(Currency, Return_Pctg)

calculoSR2 <- as.xts(calculoSR[, -1], order.by = as.Date(calculoSR$Date))

filaSR<-round(SharpeRatio(calculoSR2[, , drop = FALSE], Rf = .0003, FUN = "StdDev"), 4)
filaSR<-as.data.frame.table(filaSR)


calculonvt <- info_cuantitativa %>%
  filter(Currency %in% crypto_summary_by_currency$Currency) %>%
  group_by(Currency) %>%
  summarize(NVT = sum(`Market Cap`) / sum(Volume))
```
## Clustering
Ahora voy a añadir estos valores a crypto_summary_by_currency para hacer el clustering.

```{r}
crypto_summary_by_currency_clustering <- crypto_summary_by_currency %>% remove_rownames %>% column_to_rownames(var="Currency") 
crypto_summary_by_currency_clustering$nvt<-calculonvt$NVT
crypto_summary_by_currency_clustering$SharpeRatio<-filaSR$Freq

```

Tenemos 107 criptomonedas con 5 variables numéricas.

Para que el algoritmo de clasificación tenga sentido, es preciso normalizar cada variable, porque si no el MarketCap tendría mucho más peso.
```{r}
crypto_summary_by_currency_clustering_norm <- scale(crypto_summary_by_currency_clustering)
```


```{r}
#Vamos a usar distintas técnicas para ver el número óptimo de Clusters. Aquí visualizamos la silueta y el codo.
matDist <- daisy(crypto_summary_by_currency_clustering_norm) 
resultadosDaisy <- rep(0, 10)
resultadosCodo <- rep(0, 10)
for (i in c(2,3,4,5,6,7,8,9,10))
{
  set.seed(1234)
  ajuste           <- kmeans(crypto_summary_by_currency_clustering_norm, i)
  y_cluster     <- ajuste$cluster
  resultadosCodo[i] <- ajuste$tot.withinss
  silueta            <- silhouette(y_cluster, matDist)
  resultadosDaisy[i] <- mean(silueta[,3])
  
}
plot(2:10,resultadosDaisy[2:10],type="o",col="blue",xlab="Número de clusters",ylab="Silueta")
plot(2:10,resultadosCodo[2:10],type="o",col="blue",pch=0,xlab="Número de clusters",ylab="Elbow")
```
Por tanto, vemos que según el método de la silueta y del codo, el número ideal de clusters es 3.

Vamos a ver qué sucede con el Bouldin Index

```{r}
fviz_db <- function(data) {
  k <- c(2:10)
  nb <- NbClust(data, min.nc = 2, max.nc = 10, index = "db", method = "kmeans")
  db <- as.vector(nb$All.index)
  plot(k, db,xlab =  "Cluster number k",
       ylab = "Davies-Bouldin Score",
       main = "Davies-Bouldin Plot", cex.main=1,
       col = "dodgerblue1", cex = 0.9 ,
       lty=1 , type="o" , lwd=1, pch=4,
       bty = "l",
       las = 1, cex.axis = 0.8, tcl  = -0.2)
  abline(v=which(db==min(db)) + 1, lwd=1, col="red", lty="dashed")
}


fviz_db(crypto_summary_by_currency_clustering_norm)
```
Con Bouldin Index el valor es de 8, que es un valor también sugerido en los métodos anteriores. Por otro lado, vemos que 3 clústeres también sería una buena aproximación con este método.

Vamos con el CH (Calinski - Harabaz)

```{r}


fviz_ch <- function(data) {
  ch <- c()

  for (i in 2:10) {
    set.seed(1234)
    km <- kmeans(data, i) 
    ch[i] <- calinhara(data, 
                       km$cluster, 
                       cn=max(km$cluster) 
                       )
  }
  ch <-ch[2:10]
  k <- 2:10
  plot(k, ch,xlab =  "Cluster number k",
       ylab = "Caliński - Harabasz Score",
       main = "Caliński - Harabasz Plot", cex.main=1,
       col = "dodgerblue1", cex = 0.9 ,
       lty=1 , type="o" , lwd=1, pch=4,
       bty = "l",
       las = 1, cex.axis = 0.8, tcl  = -0.2)
  abline(v=which(ch==max(ch)) + 1, lwd=1, col="red", lty="dashed")
}

fviz_ch(crypto_summary_by_currency_clustering_norm)

```
Obtenemos unos resultados parecidos. 3 y 8 clusteres parecen buenas soluciones.

Por tanto, vamos a visualizar estas agrupaciones con el algoritmo kmeans y veamos qué agrupaciones quedan


```{r}
set.seed(1234)
result2Clusters <- kmeans(crypto_summary_by_currency_clustering_norm,centers = 2)
result2Clusters$centers
```
Vemos que se generan 2 grupos. Destaca el segundo por una altísima influencia de MarketCap.

Mostramos los resultados en forma de tabla

```{r}
result2Clusters$cluster %>%table()

result2Clusters$cluster
```

Vemos que hay un grupo muy pequeño, con solo dos elementos.

Vamos a visualizarlo.

```{r}
clusplot(crypto_summary_by_currency_clustering_norm, result2Clusters$cluster, color=T, shade=T, labels=0, lines=0)

fviz_cluster(result2Clusters, data = crypto_summary_by_currency_clustering_norm,
             palette = c("#FF0000", "#0000FF"),
             ellipse.type = "euclid", # Concentration ellipse
             star.plot = TRUE, # Add segments from centroids to items
             repel = TRUE, # Avoid label overplotting (slow)
             ggtheme = theme_minimal())
```
Lo que vemos haciendo dos grupos es que hay un grupo de dos monedas (Bitcoin y Ethereum), que son tan diferentes de las demás que es suficiente para crear un grupo. Esta conclusión es muy interesante, porque nos indica que son monedas extraordinarias.

Vamos a hacer lo mismo con 4 grupos y vemos qué sucede.

```{r}
set.seed(1234)
result4Clusters <- kmeans(crypto_summary_by_currency_clustering_norm,centers = 4)
result4Clusters$centers

result4Clusters$cluster
```


```{r}
clusplot(crypto_summary_by_currency_clustering_norm, result4Clusters$cluster, color=T, shade=T, labels=0, lines=0)

fviz_cluster(result4Clusters, data = crypto_summary_by_currency_clustering_norm,
             palette = c("#FF0000", "#0000FF",  "#000000", "#C870FF"),
             ellipse.type = "euclid", # Concentration ellipse
             star.plot = TRUE, # Add segments from centroids to items
             repel = TRUE, # Avoid label overplotting (slow)
             ggtheme = theme_minimal())
```

Al hacer cuatro grupos, vemos que se mantiene el grupo anterior de Bitcoin y Ethereum y se crea un grupo nuevo para "HEX", que tiene un valor altísimo de NVT.

El resto de las criptomonedas se dividen en los grupos 3 y 4.


Por último hago la matriz de correlaciones.
```{r}
corrplot(cor(crypto_summary_by_currency_clustering), method='number')
```
DE aquí observamos que hay una altísima correlación entre el MarketCap y el Volumen
